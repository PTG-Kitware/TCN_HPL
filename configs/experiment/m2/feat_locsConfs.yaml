# @package _global_

# to execute this experiment run:
# python train.py experiment=example
task: "m2"
# feature_version: 6
topic: "medical"

defaults:
  - override /data: ptg
  - override /model: ptg
  - override /callbacks: default
  - override /trainer: gpu
  - override /paths: default
  #- override /logger: aim
  - override /logger: csv

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# Change this name to something descriptive and unique for this experiment.
# This will differentiate the run logs and output to be separate from other
# experiments that may have been run under the configured
# Setting this value influences:
# - the name of the directory under `${paths.root_dir}/logs/` in which training
#   run files are stored.
# Default is "train" set in the "configs/train.yaml" file.
#task_name:

# simply provide checkpoint path to resume training
#ckpt_path: null

tags: ["m2", "ms_tcn", "debug"]

seed: 12345

trainer:
  min_epochs: 50
  max_epochs: 500
  log_every_n_steps: 1

model:
  compile: false
  net:
    # Length of feature vector for a single frame.
    # Currently derived from feature version and other hyperparameters.
    dim: 102
  num_classes: 9

data:
  coco_train_activities: "${paths.coco_file_root}/TRAIN-activity_truth.coco.json"
  coco_train_objects: "${paths.coco_file_root}/TRAIN-object_detections.coco.json"
  coco_train_poses: "${paths.coco_file_root}/TRAIN-pose_estimates.coco.json"

  coco_validation_activities: "${paths.coco_file_root}/VALIDATION-activity_truth.coco.json"
  coco_validation_objects: "${paths.coco_file_root}/VALIDATION-object_detections.coco.json"
  coco_validation_poses: "${paths.coco_file_root}/VALIDATION-pose_estimates.coco.json"

  coco_test_activities: "${paths.coco_file_root}/TEST-activity_truth.coco.json"
  coco_test_objects: "${paths.coco_file_root}/TEST-object_detections.coco.json"
  coco_test_poses: "${paths.coco_file_root}/TEST-pose_estimates.coco.json"

  batch_size: 16384
  num_workers: 16
  target_framerate: 15  # BBN Hololens2 Framerate
  epoch_length: 200000

  train_dataset:
    window_size: 25
    vectorizer:
      _target_: tcn_hpl.data.vectorize.locs_and_confs.LocsAndConfs
      top_k: 1
      num_classes: 7
      use_joint_confs: True
      use_pixel_norm: True
      use_hand_obj_offsets: False
      background_idx: 0
    transform:
      transforms: []  # no transforms
#        - _target_: tcn_hpl.data.components.augmentations.MoveCenterPts
#          hand_dist_delta: 0.05
#          obj_dist_delta: 0.05
#          joint_dist_delta: 0.025
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
#        - _target_: tcn_hpl.data.components.augmentations.NormalizePixelPts
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
  val_dataset:
    transform:
      transforms: []  # no transforms
#        - _target_: tcn_hpl.data.components.augmentations.NormalizePixelPts
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
  # Test dataset usually configured the same as val, unless there is some
  # different set of transforms that should be used during test/prediction.

paths:
  # root_dir: "/data/PTG/medical/training/activity_classifier/TCN_HPL/"
  # root_dir: "/home/local/KHQ/paul.tunison/data/darpa-ptg/train-TCN-M2_bbn_hololens/training_root"
  root_dir: "/home/local/KHQ/cameron.johnson/code/TCN_HPL/tcn_hpl/train-TCN-M2_bbn_hololens/training_root"

  # Convenience variable to where your train/val/test split COCO file datasets
  # are stored.
  # coco_file_root: "/home/local/KHQ/paul.tunison/data/darpa-ptg/train-TCN-M2_bbn_hololens"
  coco_file_root: "/home/local/KHQ/cameron.johnson/code/TCN_HPL/train-TCN-M2_bbn_hololens"

#exp_name: "tcn_training_revive"
#logger:
#  aim:
#    experiment: ${task_name}
#    capture_terminal_logs: true
