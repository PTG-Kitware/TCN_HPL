# @package _global_

# to execute this experiment run:
# python train.py experiment=example
topic: "medical"
task: "r18"

defaults:
  - override /data: ptg
  - override /model: ptg
  - override /callbacks: default
  - override /trainer: gpu
  - override /paths: default
  #- override /logger: aim
  - override /logger: csv

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# Change this name to something descriptive and unique for this experiment.
# This will differentiate the run logs and output to be separate from other
# experiments that may have been run under the configured
# Setting this value influences:
# - the name of the directory under `${paths.root_dir}/logs/` in which training
#   run files are stored.
# Default is "train" set in the "configs/train.yaml" file.
#task_name:

# simply provide checkpoint path to resume training
#ckpt_path: null

tags: ["r18", "ms_tcn", "debug"]

seed: 12345

trainer:
  min_epochs: 50
  max_epochs: 500
  log_every_n_steps: 1

model:
  num_classes: 6  # number of activity classification classes
  compile: false
  net:
    # Length of feature vector for a single frame.
    # Currently derived from the parameterization of dataset vectorizer.
    dim: 102

#    # Once upon a time defaults
#    num_stages: 4
#    num_layers: 10
#    num_f_maps: 64

data:
  coco_train_activities: "${paths.coco_file_root}/TRAIN-activity_truth.coco.json"
  coco_train_objects: "${paths.coco_file_root}/TRAIN-object_detections.coco.json"
  coco_train_poses: "${paths.coco_file_root}/TRAIN-pose_estimations.coco.json"

  coco_validation_activities: "${paths.coco_file_root}/VALIDATION-activity_truth.coco.json"
  coco_validation_objects: "${paths.coco_file_root}/VALIDATION-object_detections.coco.json"
  coco_validation_poses: "${paths.coco_file_root}/VALIDATION-pose_estimations.coco.json"

  coco_test_activities: "${paths.coco_file_root}/TEST-activity_truth.coco.json"
  coco_test_objects: "${paths.coco_file_root}/TEST-object_detections.coco.json"
  coco_test_poses: "${paths.coco_file_root}/TEST-pose_estimations.coco.json"

  batch_size: 512
  num_workers: 16
  target_framerate: 15  # BBN Hololens2 Framerate
  # This is a little more than the number of windows in the training dataset.
  epoch_length: 80000

  train_dataset:
    window_size: 25
    vectorize:
      _target_: tcn_hpl.data.vectorize.locs_and_confs.LocsAndConfs
      top_k: 1
      num_classes: 7
      use_joint_confs: True
      use_pixel_norm: True
      use_joint_obj_offsets: False
      background_idx: 0
    # Augmentations on windows of frame data before performing vectorization.
    transform_frame_data:
      transforms:
        - _target_: tcn_hpl.data.frame_data_aug.window_frame_dropout.DropoutFrameDataTransform
          # These parameters are a fudge for now to experiment. Window presence
          # looks qualitatively right with what we're seeing live.
          frame_rate: ${data.target_framerate}
          dets_throughput_mean: 14.5
          pose_throughput_mean: 10
          dets_latency: 0
          pose_latency: 0.1
          dets_throughput_std: 0.2
          pose_throughput_std: 0.2
  val_dataset:
    # Augmentations on windows of frame data before performing vectorization.
    # Sharing transform with training dataset as it is only the drop-out aug to
    # simulate stream processing dropout the same.
    transform_frame_data: ${data.train_dataset.transform_frame_data}
  # Test dataset usually configured the same as val, unless there is some
  # different set of transforms that should be used during test/prediction.

paths:
  # Base directory for training outputs.
  root_dir: "/data/paul.tunison/data/darpa-ptg/train-TCN-R18_bbn_hololens-yolo_v7-mmpose-window_dropout"

  # Convenience variable to where your train/val/test split COCO file datasets
  # are stored.
  coco_file_root: ${paths.root_dir}

#logger:
#  aim:
#    experiment: ${task_name}
#    capture_terminal_logs: true
