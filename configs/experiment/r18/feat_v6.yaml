# @package _global_

# to execute this experiment run:
# python train.py experiment=example
topic: "medical"
task: "r18"
feature_version: 6

defaults:
  - override /data: ptg
  - override /model: ptg
  - override /callbacks: default
  - override /trainer: gpu
  - override /paths: default
  #- override /logger: aim
  - override /logger: csv

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# Change this name to something descriptive and unique for this experiment.
# This will differentiate the run logs and output to be separate from other
# experiments that may have been run under the configured
# Setting this value influences:
# - the name of the directory under `${paths.root_dir}/logs/` in which training
#   run files are stored.
# Default is "train" set in the "configs/train.yaml" file.
#task_name:

tags: ["r18", "ms_tcn", "debug"]

seed: 12345

trainer:
  min_epochs: 50
  max_epochs: 500
  log_every_n_steps: 1

model:
  num_classes: 6  # number of activity classification classes
  compile: false
  net:
    # Length of feature vector for a single frame.
    # Currently derived from the parameterization of dataset vectorizer.
    dim: 297

# TRAINING
data:
  coco_train_activities: "${paths.coco_file_root}/TRAIN-activity_truth.coco.json"
  coco_train_objects: "${paths.coco_file_root}/TRAIN-object_detections.coco.json"
  coco_train_poses: "${paths.coco_file_root}/TRAIN-pose_estimations.coco.json"

  coco_validation_activities: "${paths.coco_file_root}/VALIDATION-activity_truth.coco.json"
  coco_validation_objects: "${paths.coco_file_root}/VALIDATION-object_detections.coco.json"
  coco_validation_poses: "${paths.coco_file_root}/VALIDATION-pose_estimations.coco.json"

  coco_test_activities: "${paths.coco_file_root}/TEST-activity_truth.coco.json"
  coco_test_objects: "${paths.coco_file_root}/TEST-object_detections.coco.json"
  coco_test_poses: "${paths.coco_file_root}/TEST-pose_estimations.coco.json"

  batch_size: 16384
  num_workers: 16
  target_framerate: 15  # BBN Hololens2 Framerate
  epoch_length: 80000

  train_dataset:
    window_size: 25
    vectorizer:
      _target_: tcn_hpl.data.vectorize.classic.Classic
      feat_version: 6
      top_k: 1
      num_classes: 7
      background_idx: 0
      hand_left_idx: 5
      hand_right_idx: 6
    transform:
      transforms: []  # no transforms
#        - _target_: tcn_hpl.data.components.augmentations.MoveCenterPts
#          hand_dist_delta: 0.05
#          obj_dist_delta: 0.05
#          joint_dist_delta: 0.025
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
#        - _target_: tcn_hpl.data.components.augmentations.NormalizePixelPts
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
  val_dataset:
    transform:
      transforms: []  # no transforms
#        - _target_: tcn_hpl.data.components.augmentations.NormalizePixelPts
#          im_w: 1280
#          im_h: 720
#          num_obj_classes: 42
#          feat_version: 2
#          top_k_objects: 1
  # Test dataset usually configured the same as val, unless there is some
  # different set of transforms that should be used during test/prediction.

paths:
  # root_dir: "/data/PTG/medical/training/activity_classifier/TCN_HPL/"
  root_dir: "/data/paul.tunison/data/darpa-ptg/train-TCN-R18_bbn_hololens-yolo_v7-mmpose"

  # Convenience variable to where your train/val/test split COCO file datasets
  # are stored.
  coco_file_root: ${paths.root_dir}

#logger:
#  aim:
#    experiment: ${task_name}
#    capture_terminal_logs: true
