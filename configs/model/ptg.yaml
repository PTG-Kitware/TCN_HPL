_target_: tcn_hpl.models.ptg_module.PTGLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.00001
  weight_decay: 0.0001

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 100000

net:
  _target_: tcn_hpl.models.components.ms_tcs_net.MultiStageModel
  fc_sequence_dims: [512, 1024, 2048]
  fc_sequence_dropout_p: 0.25
  num_stages: 4
  num_layers: 5
  num_f_maps: 128
  # dim: 204
  dim: 128
  num_classes: ${model.num_classes}

criterion:
  _target_: tcn_hpl.models.components.focal_loss.FocalLoss
  alpha: 0.25 # 0.25
  gamma: 1
  weight: None
  # weight: [1, 1, 1, 1, 1, 0.75, 0.75, 1, 1]
  # weight: [1, 1, 1, 1, 1, 1]
  reduction: "mean"

# Smoothing loss weight
smoothing_loss: 0.0015
use_smoothing_loss: False

# Number of classes
num_classes: 9

# compile model for faster training with pytorch 2.0
compile: false

# Which frame in a window of predictions should represent the while window.
pred_frame_index: -1
